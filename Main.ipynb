{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ImagePreprocessing import *\n",
    "import time\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"../snake-species-identification-challenge/data/round4_classes.csv\")\n",
    "#df1 = pd.read_csv(\"../snake-species-identification-challenge/data/train_labels.csv\",dtype={'hashed_id':str})\n",
    "#df2 = pd.read_csv(\"../snake-species-identification-challenge/data/validate_labels.csv\",dtype={'hashed_id':str})\n",
    "#df3 = pd.read_csv(\"../snake-species-identification-challenge/data/validate_labels_small.csv\",dtype={'hashed_id':str})\n",
    "#add_label(df, df1, df2, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Path settings\n",
    "train_fraction = 1\n",
    "val_fraction = 1\n",
    "data_address = \"../data/\" # Change this to load files\n",
    "train_label_filename = \"processed_train_labels.csv\"  # New Training \n",
    "val_label_filename = \"processed_validate_labels.csv\"\n",
    "val_label_small_filename = \"processed_validate_labels_small.csv\"\n",
    "\n",
    "### Load Training Set and Validation Set\n",
    "training_dataset = SnakeDataSet(filename=os.path.join(data_address,train_label_filename),image_path=os.path.join(data_address,'resized_train_images_250')) \n",
    "val_dataset = SnakeDataSet(filename=os.path.join(data_address,val_label_filename),image_path=os.path.join(data_address,'resized_val_images_250')) \n",
    "training_size = len(training_dataset)\n",
    "val_size = len(val_dataset)\n",
    "\n",
    "# There are 783 classes (0-782)\n",
    "\n",
    "### Load Set to Loader\n",
    "train_loader = DataLoader(training_dataset, batch_size=64, sampler = SubsetRandomSampler(range(int(training_size / train_fraction))))\n",
    "train_acc_loader = DataLoader(training_dataset, batch_size=64, sampler = SubsetRandomSampler(range(int(training_size / train_fraction))))\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, sampler = SubsetRandomSampler(range(int(val_size / val_fraction))))\n",
    "\n",
    "### Clear running log\n",
    "f = open('running.txt','w')\n",
    "f.truncate(0)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filepath = '../snake-species-identification-challenge/data/resized_train_images/ffffaaf775.jpg'\n",
    "#modelpath = '../snake-species-identification-challenge/alexnet_model_epoch30_lr1_batchsize64.pt'\n",
    "\n",
    "#model = initialize_model('alexnet', 783, True, use_pretrained = True)\n",
    "#model.load_state_dict(torch.load(modelpath))  \n",
    "#device = torch.device(\"cuda\")\n",
    "#model = model.float()\n",
    "#model = model.to(device)\n",
    "#model.eval()\n",
    "#for data0, target0 in val_loader:\n",
    "#    data, target = data0.to(device), target0.to(device)\n",
    "#    print(data.shape)\n",
    "#    output = model(data.float()) \n",
    "#    print(np.shape(output))\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t conv1.weight\n",
      "\t bn1.weight\n",
      "\t bn1.bias\n",
      "\t layer1.0.conv1.weight\n",
      "\t layer1.0.bn1.weight\n",
      "\t layer1.0.bn1.bias\n",
      "\t layer1.0.conv2.weight\n",
      "\t layer1.0.bn2.weight\n",
      "\t layer1.0.bn2.bias\n",
      "\t layer1.1.conv1.weight\n",
      "\t layer1.1.bn1.weight\n",
      "\t layer1.1.bn1.bias\n",
      "\t layer1.1.conv2.weight\n",
      "\t layer1.1.bn2.weight\n",
      "\t layer1.1.bn2.bias\n",
      "\t layer2.0.conv1.weight\n",
      "\t layer2.0.bn1.weight\n",
      "\t layer2.0.bn1.bias\n",
      "\t layer2.0.conv2.weight\n",
      "\t layer2.0.bn2.weight\n",
      "\t layer2.0.bn2.bias\n",
      "\t layer2.0.downsample.0.weight\n",
      "\t layer2.0.downsample.1.weight\n",
      "\t layer2.0.downsample.1.bias\n",
      "\t layer2.1.conv1.weight\n",
      "\t layer2.1.bn1.weight\n",
      "\t layer2.1.bn1.bias\n",
      "\t layer2.1.conv2.weight\n",
      "\t layer2.1.bn2.weight\n",
      "\t layer2.1.bn2.bias\n",
      "\t layer3.0.conv1.weight\n",
      "\t layer3.0.bn1.weight\n",
      "\t layer3.0.bn1.bias\n",
      "\t layer3.0.conv2.weight\n",
      "\t layer3.0.bn2.weight\n",
      "\t layer3.0.bn2.bias\n",
      "\t layer3.0.downsample.0.weight\n",
      "\t layer3.0.downsample.1.weight\n",
      "\t layer3.0.downsample.1.bias\n",
      "\t layer3.1.conv1.weight\n",
      "\t layer3.1.bn1.weight\n",
      "\t layer3.1.bn1.bias\n",
      "\t layer3.1.conv2.weight\n",
      "\t layer3.1.bn2.weight\n",
      "\t layer3.1.bn2.bias\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Random Seed\n",
    "torch.manual_seed(2020)\n",
    "np.random.seed(2020)\n",
    "\n",
    "# Fine tuning parameters\n",
    "pretrained = True\n",
    "classifier_only = False\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\")\n",
    "#model = BasicNet().to(device)          #2-layer CNN \n",
    "#model = AlexNet().to(device)           #alexnet\n",
    "model = initialize_model('resnet', 783, classifier_only)\n",
    "model = model.float()\n",
    "model = model.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if classifier_only:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
    "\n",
    "# Set your learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "# Epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/245082 (0%)]\tLoss: 6.825128\n",
      "\n",
      "Time Elapsed: 1 s.\n",
      "\n",
      "Train Epoch: 1 [32000/245082 (13%)]\tLoss: 4.383014\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 1 [64000/245082 (26%)]\tLoss: 3.785078\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 1 [96000/245082 (39%)]\tLoss: 3.947802\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 1 [128000/245082 (52%)]\tLoss: 3.301928\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 1 [160000/245082 (65%)]\tLoss: 3.553214\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 1 [192000/245082 (78%)]\tLoss: 3.315099\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 1 [224000/245082 (91%)]\tLoss: 3.658424\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 42.9824, Accuracy: 62813/245082 (26%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 42.9388, Accuracy: 3524/14021 (25%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3455.73 s.\n",
      "\n",
      "Train Epoch: 2 [0/245082 (0%)]\tLoss: 3.407383\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 2 [32000/245082 (13%)]\tLoss: 3.002714\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 2 [64000/245082 (26%)]\tLoss: 3.017300\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 2 [96000/245082 (39%)]\tLoss: 3.068230\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 2 [128000/245082 (52%)]\tLoss: 3.215440\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 2 [160000/245082 (65%)]\tLoss: 2.528665\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 2 [192000/245082 (78%)]\tLoss: 3.065929\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 2 [224000/245082 (91%)]\tLoss: 2.560529\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 70.5405, Accuracy: 93639/245082 (38%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 70.2701, Accuracy: 4984/14021 (36%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3453.06 s.\n",
      "\n",
      "Train Epoch: 3 [0/245082 (0%)]\tLoss: 2.455528\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 3 [32000/245082 (13%)]\tLoss: 2.750910\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 3 [64000/245082 (26%)]\tLoss: 2.654742\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 3 [96000/245082 (39%)]\tLoss: 2.937585\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 3 [128000/245082 (52%)]\tLoss: 2.903519\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 3 [160000/245082 (65%)]\tLoss: 3.311383\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 3 [192000/245082 (78%)]\tLoss: 2.186077\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 3 [224000/245082 (91%)]\tLoss: 2.504074\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 99.0168, Accuracy: 109555/245082 (45%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 98.5068, Accuracy: 5591/14021 (40%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3452.90 s.\n",
      "\n",
      "Train Epoch: 4 [0/245082 (0%)]\tLoss: 2.934237\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 4 [32000/245082 (13%)]\tLoss: 2.162830\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 4 [64000/245082 (26%)]\tLoss: 2.345313\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 4 [96000/245082 (39%)]\tLoss: 2.182612\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 4 [128000/245082 (52%)]\tLoss: 1.973035\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 4 [160000/245082 (65%)]\tLoss: 2.727424\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 4 [192000/245082 (78%)]\tLoss: 2.323788\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 4 [224000/245082 (91%)]\tLoss: 1.993462\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 132.8398, Accuracy: 130194/245082 (53%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 132.1433, Accuracy: 6127/14021 (44%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3453.33 s.\n",
      "\n",
      "Train Epoch: 5 [0/245082 (0%)]\tLoss: 1.828668\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 5 [32000/245082 (13%)]\tLoss: 1.901037\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 5 [64000/245082 (26%)]\tLoss: 1.376883\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 5 [96000/245082 (39%)]\tLoss: 1.884108\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 5 [128000/245082 (52%)]\tLoss: 1.975067\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 5 [160000/245082 (65%)]\tLoss: 2.778687\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 5 [192000/245082 (78%)]\tLoss: 1.591152\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 5 [224000/245082 (91%)]\tLoss: 1.485449\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 161.9626, Accuracy: 149607/245082 (61%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 160.8060, Accuracy: 6407/14021 (46%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3452.64 s.\n",
      "\n",
      "Train Epoch: 6 [0/245082 (0%)]\tLoss: 1.827882\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 6 [32000/245082 (13%)]\tLoss: 1.605203\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 6 [64000/245082 (26%)]\tLoss: 1.594162\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 6 [96000/245082 (39%)]\tLoss: 1.848309\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 6 [128000/245082 (52%)]\tLoss: 1.980707\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 6 [160000/245082 (65%)]\tLoss: 2.062411\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 6 [192000/245082 (78%)]\tLoss: 1.235945\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 6 [224000/245082 (91%)]\tLoss: 1.781129\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 171.0086, Accuracy: 165991/245082 (68%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 169.5932, Accuracy: 6487/14021 (46%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3451.95 s.\n",
      "\n",
      "Train Epoch: 7 [0/245082 (0%)]\tLoss: 1.014299\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 7 [32000/245082 (13%)]\tLoss: 1.668075\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 7 [64000/245082 (26%)]\tLoss: 1.386311\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 7 [96000/245082 (39%)]\tLoss: 1.468880\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 7 [128000/245082 (52%)]\tLoss: 1.353918\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 7 [160000/245082 (65%)]\tLoss: 1.058518\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 7 [192000/245082 (78%)]\tLoss: 0.759325\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 7 [224000/245082 (91%)]\tLoss: 0.889796\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 204.7425, Accuracy: 188485/245082 (77%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 203.0969, Accuracy: 6484/14021 (46%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3457.36 s.\n",
      "\n",
      "Train Epoch: 8 [0/245082 (0%)]\tLoss: 0.965963\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 8 [32000/245082 (13%)]\tLoss: 1.133574\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 8 [64000/245082 (26%)]\tLoss: 1.028626\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 8 [96000/245082 (39%)]\tLoss: 1.818001\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 8 [128000/245082 (52%)]\tLoss: 0.626448\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 8 [160000/245082 (65%)]\tLoss: 0.999450\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 8 [192000/245082 (78%)]\tLoss: 1.105232\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 8 [224000/245082 (91%)]\tLoss: 1.208621\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 220.8815, Accuracy: 207144/245082 (85%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 219.2458, Accuracy: 6569/14021 (47%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3455.76 s.\n",
      "\n",
      "Train Epoch: 9 [0/245082 (0%)]\tLoss: 0.694964\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 9 [32000/245082 (13%)]\tLoss: 0.767142\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 9 [64000/245082 (26%)]\tLoss: 0.768885\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 9 [96000/245082 (39%)]\tLoss: 0.775969\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 9 [128000/245082 (52%)]\tLoss: 0.763960\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 9 [160000/245082 (65%)]\tLoss: 0.915080\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 9 [192000/245082 (78%)]\tLoss: 0.505551\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 9 [224000/245082 (91%)]\tLoss: 0.459283\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 240.9872, Accuracy: 219330/245082 (89%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 239.4064, Accuracy: 6484/14021 (46%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3457.66 s.\n",
      "\n",
      "Train Epoch: 10 [0/245082 (0%)]\tLoss: 0.657996\n",
      "\n",
      "Time Elapsed: 0 s.\n",
      "\n",
      "Train Epoch: 10 [32000/245082 (13%)]\tLoss: 0.866525\n",
      "\n",
      "Time Elapsed: 234 s.\n",
      "\n",
      "Train Epoch: 10 [64000/245082 (26%)]\tLoss: 0.714721\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 10 [96000/245082 (39%)]\tLoss: 0.712362\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 10 [128000/245082 (52%)]\tLoss: 0.790291\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 10 [160000/245082 (65%)]\tLoss: 0.707862\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 10 [192000/245082 (78%)]\tLoss: 0.395900\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "Train Epoch: 10 [224000/245082 (91%)]\tLoss: 0.585918\n",
      "\n",
      "Time Elapsed: 235 s.\n",
      "\n",
      "\n",
      "Test set: Average loss: 242.8690, Accuracy: 224750/245082 (92%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 241.3072, Accuracy: 6401/14021 (46%)\n",
      "\n",
      "Time elapsed during the entire epoch: 3457.67 s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Training loop\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(1, epochs+1,1):\n",
    "    ts = time.time()\n",
    "    train(model, device, train_loader, train_fraction, optimizer, epoch, 500)\n",
    "    train_loss.append(test(model, device, train_acc_loader, train_fraction))\n",
    "    val_loss.append(test(model, device, val_loader, val_fraction))\n",
    "    scheduler.step()    # learning rate scheduler\n",
    "    \n",
    "    #Time an entire epoch\n",
    "    te = time.time()\n",
    "    message  = 'Time elapsed during the entire epoch: %.2f s.\\n'%(te-ts)\n",
    "    print(message)\n",
    "    f = open('running.txt','a')\n",
    "    f.write(message)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"pretrained_resnet_model_epoch30_lr1_batchsize64.pt\")\n",
    "f = open(\"pretrained_resnet_model_epoch30_lr1_batchsize64_accuracy.txt\",\"w\")\n",
    "f.write('Training Loss: ' + ' '.join(str(_) for _ in train_loss) + '\\n')\n",
    "f.write('Validation Loss: ' + ' '.join(str(_) for _ in val_loss) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
